# 機械学習の種類
- クラス分類
- 回帰

# K-最近傍法
- 予測したいデータポイントに最も近い点（近傍点）のクラスと同等のクラスを与える
- 近傍点が複数ある場合には，与えられるクラスは多数決で決まる

# KNeighborsClassifierの解析
- 平面に対して，そこに点があった場合に分類されていたであろうクラスに従って色をつける（決定境界）
- 近傍点数が多いほど複雑なモデル（過剰適合）となり，逆に近傍点数が少ないほど単純なモデル（適合不足）となる
- 決定境界に限った話ではないが，過剰適合でもなく適合不足でもない汎化されたモデルが必要

# K-近傍回帰
- K-最近傍法を用いて回帰アルゴリズムを行うことも可能である
- 考慮する近傍点数の平均値をとったデータポイントを予測点とする

# KNeighborsRegressorの解析
- 1次元のデータセットに対して，全ての値に対する予測値をみる
- 近傍点数が多いほど適合度は上がるが，予測は不安定になる
- 近傍点数が少ないほど適合度は低くなるが，予測はスムーズになる
- つまりこれも過剰適合や適合不足的な話
