# 線形モデルとは
- 線型関数を用いて予測を行うもの
- y = w[0] × x[0] + w[1] × x[1] + ・・・w[p] × x[p] + bを用いて表される
- w[0]は傾き，bは切片を表すため，w≈coef_ b≈interceptと考えるといいかも

# リッジ回帰
- L2正則化を用いて，線形回帰での過剰適合を防ぐ
- L2正則化はwの要素を0に近づけ，特徴量の影響を少なくする
- L2正則化ではalphaパラメータを用いる
- alphaパラメータが大きくなると，単純なモデルになる
- サンプル数が多い時には，L2正則化はあまり効果がない

# Lasso回帰
- L1正則化を用いて，線形回帰での過剰適合を防ぐ
- L1正則化はいくつかのwを完全に0にすることで，特徴量の影響を少なくする
- L1正則化でもalphaパラメータを用いる
- 少量の特徴量のみをしようするため，モデルの解釈が簡単

# 線形モデルの2クラス分類
- 決定境界線による2クラス分類を行う
- y = w[0] × x[0] + w[1] × x[1] + ・・・ + w[p] × x[p] + b > 0を用いて表される
- ロジスティック回帰(LogisticRegression)と線形サポートベクタマシン(LinearSVC)の2種類がある
- 正則化にはL2正則化が用いられる
- Cパラメータを用いる
- Cパラメータが小さいと，単純なモデルになる

# 線形モデルの多クラス分類
- 1対その他アプローチを用いる
- y = w[0] × x[0] + w[1] × x[1] + ・・・ + w[p] × x[p] + bを用いて表される
- 上記の式はコード上でも使用されるため，特に重要
